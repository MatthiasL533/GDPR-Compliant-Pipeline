{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0d289df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Read the CSV files into DataFrames\n",
    "df_original = pd.read_csv('originaldf.csv')\n",
    "df_noisy1 = pd.read_csv('df-noisy1.csv')\n",
    "df_noisy2 = pd.read_csv('df-noisy2.csv')\n",
    "df_noisy3 = pd.read_csv('df-noisy3.csv')\n",
    "df_noisy4 = pd.read_csv('df-noisy4.csv')\n",
    "df_noisy5 = pd.read_csv('df-noisy5.csv')\n",
    "df_noisy6 = pd.read_csv('df-noisy6.csv')\n",
    "df_noisy7 = pd.read_csv('df-noisy7.csv')\n",
    "df_noisy8 = pd.read_csv('df-noisy8.csv')\n",
    "\n",
    "dft1= pd.read_csv('df1-v.csv')\n",
    "dft2= pd.read_csv('df2-v.csv')\n",
    "dft3= pd.read_csv('df3-v.csv')\n",
    "dft4= pd.read_csv('df4-v.csv')\n",
    "dft5= pd.read_csv('df5-v.csv')\n",
    "\n",
    "\n",
    "readmitted_mapping = {'<30': 1, '>30': 0, 'NO': 0}\n",
    "\n",
    "# Apply the mapping to 'readmitted' column in each DataFrame\n",
    "df_original['readmitted'] = df_original['readmitted'].map(readmitted_mapping)\n",
    "df_noisy1['readmitted'] = df_noisy1['readmitted'].map(readmitted_mapping)\n",
    "df_noisy2['readmitted'] = df_noisy2['readmitted'].map(readmitted_mapping)\n",
    "df_noisy3['readmitted'] = df_noisy3['readmitted'].map(readmitted_mapping)\n",
    "df_noisy4['readmitted'] = df_noisy4['readmitted'].map(readmitted_mapping)\n",
    "df_noisy5['readmitted'] = df_noisy5['readmitted'].map(readmitted_mapping)\n",
    "df_noisy6['readmitted'] = df_noisy6['readmitted'].map(readmitted_mapping)\n",
    "df_noisy7['readmitted'] = df_noisy7['readmitted'].map(readmitted_mapping)\n",
    "df_noisy8['readmitted'] = df_noisy8['readmitted'].map(readmitted_mapping)\n",
    "\n",
    "dft1['readmitted'] = dft1['readmitted'].map(readmitted_mapping)\n",
    "dft2['readmitted'] = dft2['readmitted'].map(readmitted_mapping)\n",
    "dft3['readmitted'] = dft3['readmitted'].map(readmitted_mapping)\n",
    "dft4['readmitted'] = dft4['readmitted'].map(readmitted_mapping)\n",
    "dft5['readmitted'] = dft5['readmitted'].map(readmitted_mapping)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ccb6231",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def encode_categorical_features(df, exclude_columns=None):\n",
    "    \"\"\"Encode categorical features using dummy encoding or binary encoding based on the number of unique values,\n",
    "    while excluding specified columns from encoding.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame containing features to be encoded.\n",
    "        exclude_columns (list): List of columns to exclude from encoding.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with encoded features.\n",
    "        dict: Dictionary mapping each original column name to the encoding type used.\n",
    "    \"\"\"\n",
    "    encoded_df = df.copy()\n",
    "    encoding_info = {}\n",
    "    if exclude_columns is None:\n",
    "        exclude_columns = []\n",
    "    \n",
    "    categorical_columns = encoded_df.select_dtypes(include=['object', 'category']).columns\n",
    "    \n",
    "    for column in categorical_columns:\n",
    "        if column in exclude_columns:\n",
    "            encoding_info[column] = \"Excluded\"\n",
    "            continue\n",
    "        \n",
    "        unique_values = encoded_df[column].nunique()\n",
    "        if unique_values == 2 or unique_values == 1:\n",
    "            value_mapping = {label: idx for idx, label in enumerate(encoded_df[column].unique())}\n",
    "            encoded_df[column] = encoded_df[column].map(value_mapping)\n",
    "            encoding_info[column] = \"Binary Encoding\"\n",
    "        elif unique_values >= 3:\n",
    "            dummies = pd.get_dummies(encoded_df[column], prefix=column)\n",
    "            encoded_df = pd.concat([encoded_df, dummies], axis=1)\n",
    "            encoded_df.drop(column, axis=1, inplace=True)\n",
    "            encoding_info[column] = \"Dummy Encoding\"\n",
    "    \n",
    "    return encoded_df, encoding_info\n",
    "\n",
    "def run_multivariable_logistic_regression(encoded_df, target_column):\n",
    "    \"\"\"\n",
    "    Runs a Multivariable Logistic Regression model on the provided encoded DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    - encoded_df: The encoded DataFrame.\n",
    "    - target_column: The name of the target column in the DataFrame.\n",
    "    \n",
    "    Returns:\n",
    "    - dict: Dictionary containing the model, accuracy, and predictions.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        X = encoded_df.drop(target_column, axis=1)\n",
    "        y = encoded_df[target_column]\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        model = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000, random_state=42)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        accuracy = model.score(X_test, y_test)\n",
    "        predictions = model.predict(X_test)\n",
    "\n",
    "        return {\n",
    "            \"model\": model,\n",
    "            \"accuracy\": accuracy,\n",
    "            \"predictions\": predictions,\n",
    "            \"model_name\": \"Multivariable Logistic Regression\"\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error running Multivariable Logistic Regression: {e}\")\n",
    "        return None\n",
    "\n",
    "def run_random_forest(encoded_df, target_column):\n",
    "    \"\"\"\n",
    "    Runs a Random Forest model on the provided encoded DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    - encoded_df: The encoded DataFrame.\n",
    "    - target_column: The name of the target column in the DataFrame.\n",
    "    \n",
    "    Returns:\n",
    "    - dict: Dictionary containing the model, accuracy, and predictions.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        X = encoded_df.drop(target_column, axis=1)\n",
    "        y = encoded_df[target_column]\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        accuracy = model.score(X_test, y_test)\n",
    "        predictions = model.predict(X_test)\n",
    "\n",
    "        return {\n",
    "            \"model\": model,\n",
    "            \"accuracy\": accuracy,\n",
    "            \"predictions\": predictions,\n",
    "            \"model_name\": \"Random Forest\"\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error running Random Forest: {e}\")\n",
    "        return None\n",
    "\n",
    "def run_ml_models(encoded_df, target_column):\n",
    "    \"\"\"\n",
    "    Runs both Multivariable Logistic Regression and Random Forest models on the provided encoded DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    - encoded_df: The encoded DataFrame.\n",
    "    - target_column: The name of the target column in the DataFrame.\n",
    "    \n",
    "    Returns:\n",
    "    - dict: Dictionary containing the results for both models.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    lr_result = run_multivariable_logistic_regression(encoded_df, target_column)\n",
    "    if lr_result is not None:\n",
    "        results[\"Multivariable Logistic Regression\"] = lr_result\n",
    "        print(f\"Accuracy for Multivariable Logistic Regression: {lr_result['accuracy']:.2f}\")\n",
    "\n",
    "    rf_result = run_random_forest(encoded_df, target_column)\n",
    "    if rf_result is not None:\n",
    "        results[\"Random Forest\"] = rf_result\n",
    "        print(f\"Accuracy for Random Forest: {rf_result['accuracy']:.2f}\")\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a04f1262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding Information:\n",
      "race: Dummy Encoding\n",
      "gender: Binary Encoding\n",
      "age: Dummy Encoding\n",
      "discharge_disposition_id: Dummy Encoding\n",
      "admission_source_id: Dummy Encoding\n",
      "diag_1: Dummy Encoding\n",
      "diag_2: Dummy Encoding\n",
      "diag_3: Dummy Encoding\n",
      "max_glu_serum: Dummy Encoding\n",
      "A1Cresult: Dummy Encoding\n",
      "metformin: Dummy Encoding\n",
      "repaglinide: Dummy Encoding\n",
      "nateglinide: Dummy Encoding\n",
      "chlorpropamide: Dummy Encoding\n",
      "glimepiride: Dummy Encoding\n",
      "acetohexamide: Binary Encoding\n",
      "glipizide: Dummy Encoding\n",
      "glyburide: Dummy Encoding\n",
      "tolbutamide: Binary Encoding\n",
      "pioglitazone: Dummy Encoding\n",
      "rosiglitazone: Dummy Encoding\n",
      "acarbose: Dummy Encoding\n",
      "miglitol: Dummy Encoding\n",
      "troglitazone: Binary Encoding\n",
      "tolazamide: Dummy Encoding\n",
      "examide: Binary Encoding\n",
      "citoglipton: Binary Encoding\n",
      "insulin: Dummy Encoding\n",
      "glyburide-metformin: Dummy Encoding\n",
      "glipizide-metformin: Binary Encoding\n",
      "glimepiride-pioglitazone: Binary Encoding\n",
      "metformin-rosiglitazone: Binary Encoding\n",
      "metformin-pioglitazone: Binary Encoding\n",
      "change: Binary Encoding\n",
      "diabetesMed: Binary Encoding\n",
      "\n",
      "Encoded DataFrame:\n",
      "   gender  admission_type_id  time_in_hospital  num_lab_procedures  \\\n",
      "0       0                  0                 1                  41   \n",
      "1       0                  1                 3                  59   \n",
      "2       0                  1                 2                  11   \n",
      "3       1                  1                 2                  44   \n",
      "4       1                  1                 1                  51   \n",
      "\n",
      "   num_procedures  num_medications  number_outpatient  number_emergency  \\\n",
      "0               0                1                  0                 0   \n",
      "1               0               18                  0                 0   \n",
      "2               5               13                  2                 0   \n",
      "3               1               16                  0                 0   \n",
      "4               0                8                  0                 0   \n",
      "\n",
      "   number_inpatient  number_diagnoses  ...  tolazamide_Steady  tolazamide_Up  \\\n",
      "0                 0                 1  ...                  0              0   \n",
      "1                 0                 9  ...                  0              0   \n",
      "2                 1                 6  ...                  0              0   \n",
      "3                 0                 7  ...                  0              0   \n",
      "4                 0                 5  ...                  0              0   \n",
      "\n",
      "   insulin_Down  insulin_No  insulin_Steady  insulin_Up  \\\n",
      "0             0           1               0           0   \n",
      "1             0           0               0           1   \n",
      "2             0           1               0           0   \n",
      "3             0           0               0           1   \n",
      "4             0           0               1           0   \n",
      "\n",
      "   glyburide-metformin_Down  glyburide-metformin_No  \\\n",
      "0                         0                       1   \n",
      "1                         0                       1   \n",
      "2                         0                       1   \n",
      "3                         0                       1   \n",
      "4                         0                       1   \n",
      "\n",
      "   glyburide-metformin_Steady  glyburide-metformin_Up  \n",
      "0                           0                       0  \n",
      "1                           0                       0  \n",
      "2                           0                       0  \n",
      "3                           0                       0  \n",
      "4                           0                       0  \n",
      "\n",
      "[5 rows x 141 columns]\n"
     ]
    }
   ],
   "source": [
    "# Encode categorical features in the original dataset\n",
    "encoded_df, encoding_info = encode_categorical_features(df_original, exclude_columns=['readmitted'])\n",
    "\n",
    "# Print encoding information\n",
    "print(\"Encoding Information:\")\n",
    "for column, encoding_type in encoding_info.items():\n",
    "    print(f\"{column}: {encoding_type}\")\n",
    "\n",
    "# Display encoded DataFrame\n",
    "print(\"\\nEncoded DataFrame:\")\n",
    "print(encoded_df.head())\n",
    "\n",
    "# Optionally, encode categorical features in noisy datasets\n",
    "encoded_noisy_dfs = []\n",
    "for df_noisy in [df_noisy1, df_noisy2, df_noisy3, df_noisy4, df_noisy5, df_noisy6, df_noisy7, df_noisy8]:\n",
    "    encoded_noisy_df, _ = encode_categorical_features(df_noisy, exclude_columns=['readmitted'])\n",
    "    encoded_noisy_dfs.append(encoded_noisy_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a6a929dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for Original Dataset:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fanfan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1237: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/Users/fanfan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Multivariable Logistic Regression: 0.89\n",
      "Accuracy for Random Forest: 0.89\n",
      "\n",
      "Results:\n",
      "\n",
      "Multivariable Logistic Regression Results:\n",
      "Accuracy: 0.88847\n",
      "Predictions: [0 0 0 ... 1 0 0]\n",
      "\n",
      "Random Forest Results:\n",
      "Accuracy: 0.88916\n",
      "Predictions: [0 0 0 ... 0 0 0]\n",
      "\n",
      "Results for Noisy1 Dataset:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fanfan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1237: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/Users/fanfan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Multivariable Logistic Regression: 0.89\n",
      "Accuracy for Random Forest: 0.89\n",
      "Multivariable Logistic Regression Accuracy: 0.88786\n",
      "Random Forest Accuracy: 0.88786\n",
      "\n",
      "Results for Noisy2 Dataset:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fanfan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1237: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/Users/fanfan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Multivariable Logistic Regression: 0.89\n",
      "Accuracy for Random Forest: 0.89\n",
      "Multivariable Logistic Regression Accuracy: 0.88762\n",
      "Random Forest Accuracy: 0.88762\n",
      "\n",
      "Results for Noisy3 Dataset:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fanfan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1237: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/Users/fanfan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Multivariable Logistic Regression: 0.89\n",
      "Accuracy for Random Forest: 0.89\n",
      "Multivariable Logistic Regression Accuracy: 0.88843\n",
      "Random Forest Accuracy: 0.88843\n",
      "\n",
      "Results for Noisy4 Dataset:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fanfan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1237: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/Users/fanfan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Multivariable Logistic Regression: 0.89\n",
      "Accuracy for Random Forest: 0.89\n",
      "Multivariable Logistic Regression Accuracy: 0.88872\n",
      "Random Forest Accuracy: 0.88872\n",
      "\n",
      "Results for Noisy5 Dataset:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fanfan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1237: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/Users/fanfan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Multivariable Logistic Regression: 0.89\n",
      "Accuracy for Random Forest: 0.89\n",
      "Multivariable Logistic Regression Accuracy: 0.88872\n",
      "Random Forest Accuracy: 0.88872\n",
      "\n",
      "Results for Noisy6 Dataset:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fanfan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1237: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/Users/fanfan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Multivariable Logistic Regression: 0.89\n",
      "Accuracy for Random Forest: 0.89\n",
      "Multivariable Logistic Regression Accuracy: 0.88852\n",
      "Random Forest Accuracy: 0.88852\n",
      "\n",
      "Results for Noisy7 Dataset:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fanfan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1237: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/Users/fanfan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Multivariable Logistic Regression: 0.89\n",
      "Accuracy for Random Forest: 0.89\n",
      "Multivariable Logistic Regression Accuracy: 0.88852\n",
      "Random Forest Accuracy: 0.88852\n",
      "\n",
      "Results for Noisy8 Dataset:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fanfan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1237: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/Users/fanfan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Multivariable Logistic Regression: 0.89\n",
      "Accuracy for Random Forest: 0.89\n",
      "Multivariable Logistic Regression Accuracy: 0.88852\n",
      "Random Forest Accuracy: 0.88852\n"
     ]
    }
   ],
   "source": [
    "\n",
    "target_column = 'readmitted'\n",
    "\n",
    "# Run models on the original dataset\n",
    "print(\"\\nResults for Original Dataset:\")\n",
    "results_original = run_ml_models(encoded_df, target_column)\n",
    "\n",
    "# Print results for original dataset\n",
    "print(\"\\nResults:\")\n",
    "for model_name, result in results_original.items():\n",
    "    print(f\"\\n{model_name} Results:\")\n",
    "    print(f\"Accuracy: {result['accuracy']:.5f}\")\n",
    "    print(f\"Predictions: {result['predictions']}\")\n",
    "\n",
    "# Optionally, run models on each noisy dataset\n",
    "for i, encoded_noisy_df in enumerate(encoded_noisy_dfs, start=1):\n",
    "    print(f\"\\nResults for Noisy{i} Dataset:\")\n",
    "    noisy_results = run_ml_models(encoded_noisy_df, target_column)\n",
    "    for model_name, result in noisy_results.items():\n",
    "        print(f\"{model_name} Accuracy: {result['accuracy']:.5f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1721c380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Logistic Regression  Random Forest\n",
      "Dataset                                     \n",
      "Original              0.88852        0.88916\n",
      "Noisy1                0.88786        0.88786\n",
      "Noisy2                0.88762        0.88762\n",
      "Noisy3                0.88843        0.88843\n",
      "Noisy4                0.88872        0.88872\n",
      "Noisy5                0.88872        0.88872\n",
      "Noisy6                0.88852        0.88852\n",
      "Noisy7                0.88852        0.88852\n",
      "Noisy8                0.88852        0.88852\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a dictionary with the results\n",
    "results_dict = {\n",
    "    \"Dataset\": [\"Original\", \"Noisy1\", \"Noisy2\", \"Noisy3\", \"Noisy4\", \"Noisy5\", \"Noisy6\", \"Noisy7\", \"Noisy8\"],\n",
    "    \"Logistic Regression\": [0.88852, 0.88786, 0.88762, 0.88843, 0.88872, 0.88872, 0.88852, 0.88852, 0.88852],\n",
    "    \"Random Forest\": [0.88916, 0.88786, 0.88762, 0.88843, 0.88872, 0.88872, 0.88852, 0.88852, 0.88852]\n",
    "}\n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "results_df = pd.DataFrame(results_dict)\n",
    "\n",
    "# Set 'Dataset' as index (optional, but can be useful for certain operations)\n",
    "results_df.set_index('Dataset', inplace=True)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8f8621",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
