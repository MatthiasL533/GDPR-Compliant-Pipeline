{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f05fef0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>admission_type_id</th>\n",
       "      <th>discharge_disposition_id</th>\n",
       "      <th>admission_source_id</th>\n",
       "      <th>time_in_hospital</th>\n",
       "      <th>num_lab_procedures</th>\n",
       "      <th>num_procedures</th>\n",
       "      <th>num_medications</th>\n",
       "      <th>...</th>\n",
       "      <th>citoglipton</th>\n",
       "      <th>insulin</th>\n",
       "      <th>glyburide-metformin</th>\n",
       "      <th>glipizide-metformin</th>\n",
       "      <th>glimepiride-pioglitazone</th>\n",
       "      <th>metformin-rosiglitazone</th>\n",
       "      <th>metformin-pioglitazone</th>\n",
       "      <th>change</th>\n",
       "      <th>diabetesMed</th>\n",
       "      <th>readmitted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>[0-20)</td>\n",
       "      <td>0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Referral</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>[0-20)</td>\n",
       "      <td>1</td>\n",
       "      <td>Home</td>\n",
       "      <td>Other</td>\n",
       "      <td>3</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Up</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>&gt;30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AfricanAmerican</td>\n",
       "      <td>Female</td>\n",
       "      <td>[20-40)</td>\n",
       "      <td>1</td>\n",
       "      <td>Home</td>\n",
       "      <td>Other</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[20-40)</td>\n",
       "      <td>1</td>\n",
       "      <td>Home</td>\n",
       "      <td>Other</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Up</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[40-50)</td>\n",
       "      <td>1</td>\n",
       "      <td>Home</td>\n",
       "      <td>Other</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Steady</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              race  gender      age  admission_type_id  \\\n",
       "0        Caucasian  Female   [0-20)                  0   \n",
       "1        Caucasian  Female   [0-20)                  1   \n",
       "2  AfricanAmerican  Female  [20-40)                  1   \n",
       "3        Caucasian    Male  [20-40)                  1   \n",
       "4        Caucasian    Male  [40-50)                  1   \n",
       "\n",
       "  discharge_disposition_id admission_source_id  time_in_hospital  \\\n",
       "0                  Unknown            Referral                 1   \n",
       "1                     Home               Other                 3   \n",
       "2                     Home               Other                 2   \n",
       "3                     Home               Other                 2   \n",
       "4                     Home               Other                 1   \n",
       "\n",
       "   num_lab_procedures  num_procedures  num_medications  ...  citoglipton  \\\n",
       "0                  41               0                1  ...           No   \n",
       "1                  59               0               18  ...           No   \n",
       "2                  11               5               13  ...           No   \n",
       "3                  44               1               16  ...           No   \n",
       "4                  51               0                8  ...           No   \n",
       "\n",
       "   insulin  glyburide-metformin glipizide-metformin glimepiride-pioglitazone  \\\n",
       "0       No                   No                  No                       No   \n",
       "1       Up                   No                  No                       No   \n",
       "2       No                   No                  No                       No   \n",
       "3       Up                   No                  No                       No   \n",
       "4   Steady                   No                  No                       No   \n",
       "\n",
       "  metformin-rosiglitazone  metformin-pioglitazone change diabetesMed  \\\n",
       "0                      No                      No     No          No   \n",
       "1                      No                      No     Ch         Yes   \n",
       "2                      No                      No     No         Yes   \n",
       "3                      No                      No     Ch         Yes   \n",
       "4                      No                      No     Ch         Yes   \n",
       "\n",
       "  readmitted  \n",
       "0         NO  \n",
       "1        >30  \n",
       "2         NO  \n",
       "3         NO  \n",
       "4         NO  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv('df5.csv')\n",
    "\n",
    "# Display the DataFrame to verify the columns have been dropped\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9b54784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P_29 Score: 0.0\n",
      "Reasons: ['normalized entropy l-value is 0 for some attribute', 't-value exceeds 0.5 for some attribute']\n",
      "Problematic Information:\n",
      "Problem in race: AfricanAmerican, gender: Female, age: [0-20) due to normalized entropy l-value is 0 for Normalized Entropy l-diversity_max_glu_serum\n",
      "Problem in race: other, gender: Female, age: [0-20) due to normalized entropy l-value is 0 for Normalized Entropy l-diversity_max_glu_serum\n",
      "Problem in race: other, gender: Male, age: [0-20) due to normalized entropy l-value is 0 for Normalized Entropy l-diversity_max_glu_serum\n",
      "Problem in race: AfricanAmerican, gender: Female, age: [0-20) due to t-value exceeds 0.5 for t-closeness_diag_1\n",
      "Problem in race: AfricanAmerican, gender: Male, age: [0-20) due to t-value exceeds 0.5 for t-closeness_diag_1\n",
      "Problem in race: Caucasian, gender: Female, age: [0-20) due to t-value exceeds 0.5 for t-closeness_diag_1\n",
      "Problem in race: Caucasian, gender: Male, age: [0-20) due to t-value exceeds 0.5 for t-closeness_diag_1\n",
      "Problem in race: other, gender: Female, age: [0-20) due to t-value exceeds 0.5 for t-closeness_diag_1\n",
      "Problem in race: other, gender: Male, age: [0-20) due to t-value exceeds 0.5 for t-closeness_diag_1\n",
      "Problem in race: Caucasian, gender: Female, age: [0-20) due to t-value exceeds 0.5 for t-closeness_diag_2\n",
      "Problem in race: Caucasian, gender: Male, age: [0-20) due to t-value exceeds 0.5 for t-closeness_diag_2\n",
      "Minimum k-anonymity: 26\n",
      "Minimum normalized l-value: 0.0\n",
      "Maximum t-value: 0.6411724343305779\n"
     ]
    }
   ],
   "source": [
    "#Check the P_29 Score\n",
    "\n",
    "\n",
    "def calculate_k_anonymity(group):\n",
    "    return len(group)\n",
    "\n",
    "def calculate_normalized_entropy(series):\n",
    "    if series.empty:\n",
    "        return 0\n",
    "\n",
    "    value_counts = series.value_counts(normalize=True)\n",
    "    total_entropy = 0\n",
    "\n",
    "    for count in value_counts:\n",
    "        if count > 0:\n",
    "            total_entropy -= count * np.log2(count)\n",
    "\n",
    "    unique_values = series.nunique()\n",
    "    if unique_values == 1:\n",
    "        return 0\n",
    "\n",
    "    normalized_entropy = total_entropy / np.log2(unique_values)\n",
    "    return normalized_entropy\n",
    "\n",
    "def calculate_global_distribution(series):\n",
    "    class_distribution = series.value_counts(normalize=True)\n",
    "    global_distribution = class_distribution.to_dict()\n",
    "    return global_distribution\n",
    "\n",
    "def compute_t_closeness(series, global_distribution):\n",
    "    class_distribution = series.value_counts(normalize=True)\n",
    "    combined_index = list(global_distribution.keys())\n",
    "    class_distribution = class_distribution.reindex(combined_index, fill_value=0)\n",
    "\n",
    "    p_values = class_distribution.values\n",
    "    q_values = np.array([global_distribution.get(k, 0) for k in combined_index])\n",
    "\n",
    "    t_closeness = 0.5 * np.sum(np.abs(p_values - q_values))\n",
    "    return t_closeness\n",
    "\n",
    "def calculate_t_closeness(df, quasi_identifiers, sensitive_attributes):\n",
    "    results = []\n",
    "\n",
    "    grouped = df.groupby(quasi_identifiers)\n",
    "    global_distributions = {attribute: calculate_global_distribution(df[attribute]) for attribute in sensitive_attributes}\n",
    "\n",
    "    for group_name, group_df in grouped:\n",
    "        t_closeness_values = {}\n",
    "        for attribute in sensitive_attributes:\n",
    "            series = group_df[attribute]\n",
    "            t_closeness = compute_t_closeness(series, global_distributions[attribute])\n",
    "            t_closeness_values[f't-closeness_{attribute}'] = t_closeness\n",
    "\n",
    "        group_result = {\n",
    "            'Quasi-identifiers': ', '.join(f\"{qi}: {value}\" for qi, value in zip(quasi_identifiers, group_name)),\n",
    "            **t_closeness_values\n",
    "        }\n",
    "        results.append(group_result)\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    return results_df\n",
    "\n",
    "def calculate_P_29_score(k_value, l_value, t_value, w_k=0.5, w_l=0.25, w_t=0.25):\n",
    "    reasons = []\n",
    "    problematic_info = []\n",
    "\n",
    "    k_min = k_value['k-anonymity'].min()\n",
    "\n",
    "    if k_min == 1:\n",
    "        reasons.append(\"k-anonymity is 1\")\n",
    "        problematic_rows = k_value[k_value['k-anonymity'] == 1]['Quasi-identifiers'].tolist()\n",
    "        problematic_info.extend([(row, \"k-anonymity is 1\") for row in problematic_rows])\n",
    "\n",
    "    if l_value.iloc[:, 1:].eq(0).any().any():\n",
    "        reasons.append(\"normalized entropy l-value is 0 for some attribute\")\n",
    "        for col in l_value.columns[1:]:\n",
    "            problematic_rows = l_value[l_value[col] == 0]['Quasi-identifiers'].tolist()\n",
    "            problematic_info.extend([(row, f\"normalized entropy l-value is 0 for {col}\") for row in problematic_rows])\n",
    "\n",
    "    if (t_value.iloc[:, 1:].astype(float) > 0.5).any().any():\n",
    "        reasons.append(\"t-value exceeds 0.5 for some attribute\")\n",
    "        for col in t_value.columns[1:]:\n",
    "            if t_value[col].dtype != 'object':\n",
    "                problematic_rows = t_value[t_value[col].astype(float) > 0.5]['Quasi-identifiers'].tolist()\n",
    "                problematic_info.extend([(row, f\"t-value exceeds 0.5 for {col}\") for row in problematic_rows])\n",
    "\n",
    "    if k_min == 1 or l_value.iloc[:, 1:].eq(0).any().any() or (t_value.iloc[:, 1:].astype(float) > 0.5).any().any():\n",
    "        return 0.0, problematic_info, reasons, k_min, l_value.iloc[:, 1:].min().min(), t_value.iloc[:, 1:].max().max()\n",
    "\n",
    "    column_means = l_value.iloc[:, 1:].mean()\n",
    "    normalized_l_value = column_means.mean()\n",
    "\n",
    "    t_value_normalized = t_value.copy()\n",
    "    for column in t_value.columns[1:]:\n",
    "        min_val = t_value[column].min()\n",
    "        max_val = t_value[column].max()\n",
    "        t_value_normalized[column] = (t_value[column] - min_val) / (max_val - min_val)\n",
    "\n",
    "    normalized_t_value = t_value_normalized.iloc[:, 1:].mean().mean()\n",
    "\n",
    "    P_29_score = w_k * (1 - (1 / k_min)) + w_l * normalized_l_value + w_t * (1 - normalized_t_value)\n",
    "\n",
    "    return P_29_score, problematic_info, reasons, k_min, l_value.iloc[:, 1:].min().min(), t_value.iloc[:, 1:].max().max()\n",
    "\n",
    "def analyze_privacy(df, quasi_identifiers, sensitive_attributes):\n",
    "    results = defaultdict(list)\n",
    "\n",
    "    grouped = df.groupby(quasi_identifiers)\n",
    "    for name, group in grouped:\n",
    "        k_anonymity = calculate_k_anonymity(group)\n",
    "\n",
    "        for attribute in sensitive_attributes:\n",
    "            normalized_entropy = calculate_normalized_entropy(group[attribute])\n",
    "            results[f'Normalized Entropy l-diversity_{attribute}'].append(normalized_entropy)\n",
    "\n",
    "        quasi_identifier_values = ', '.join(f\"{qi}: {group[qi].iloc[0]}\" for qi in quasi_identifiers)\n",
    "        results['Quasi-identifiers'].append(quasi_identifier_values)\n",
    "        results['k-anonymity'].append(k_anonymity)\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    t_value = calculate_t_closeness(df, quasi_identifiers, sensitive_attributes)\n",
    "\n",
    "    k_value = results_df[['Quasi-identifiers', 'k-anonymity']].copy()\n",
    "    l_value_columns = ['Quasi-identifiers'] + [col for col in results_df.columns if col.startswith('Normalized Entropy l-diversity')]\n",
    "    l_value = results_df[l_value_columns].copy()\n",
    "\n",
    "    P_29_score, problematic_info, reasons, k_min, min_l_value, max_t_value = calculate_P_29_score(k_value, l_value, t_value)\n",
    "\n",
    "    return {\n",
    "        \"P_29_score\": P_29_score,\n",
    "        \"problematic_info\": problematic_info,\n",
    "        \"reasons\": reasons,\n",
    "        \"k_min\": k_min,\n",
    "        \"min_l_value\": min_l_value,\n",
    "        \"max_t_value\": max_t_value,\n",
    "        \"k_value\": k_value,\n",
    "        \"l_value\": l_value,\n",
    "        \"t_value\": t_value\n",
    "    }\n",
    "\n",
    "# Example usage:\n",
    "# Assuming `df` is the DataFrame with your data\n",
    "quasi_identifiers = ['race', 'gender', 'age']\n",
    "sensitive_attributes = ['diag_1', 'diag_2', 'diag_3', 'max_glu_serum', 'A1Cresult', 'readmitted']\n",
    "\n",
    "# Calculate privacy metrics and P_29 score\n",
    "privacy_results = analyze_privacy(df, quasi_identifiers, sensitive_attributes)\n",
    "\n",
    "# Display results\n",
    "print(\"P_29 Score:\", privacy_results[\"P_29_score\"])\n",
    "print(\"Reasons:\", privacy_results[\"reasons\"])\n",
    "print(\"Problematic Information:\")\n",
    "for info in privacy_results[\"problematic_info\"]:\n",
    "    print(f\"Problem in {info[0]} due to {info[1]}\")\n",
    "print(\"Minimum k-anonymity:\", privacy_results[\"k_min\"])\n",
    "print(\"Minimum normalized l-value:\", privacy_results[\"min_l_value\"])\n",
    "print(\"Maximum t-value:\", privacy_results[\"max_t_value\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42e25ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered DataFrame:\n",
      "                   race  gender       age  admission_type_id  \\\n",
      "2       AfricanAmerican  Female   [20-40)                  1   \n",
      "3             Caucasian    Male   [20-40)                  1   \n",
      "4             Caucasian    Male   [40-50)                  1   \n",
      "5             Caucasian    Male   [50-60)                  1   \n",
      "6             Caucasian    Male   [60-70)                  1   \n",
      "...                 ...     ...       ...                ...   \n",
      "101758  AfricanAmerican    Male   [70-80)                  1   \n",
      "101759  AfricanAmerican  Female  [80-100)                  1   \n",
      "101760        Caucasian    Male   [70-80)                  1   \n",
      "101761        Caucasian  Female  [80-100)                  1   \n",
      "101762        Caucasian    Male   [70-80)                  1   \n",
      "\n",
      "       discharge_disposition_id admission_source_id  time_in_hospital  \\\n",
      "2                          Home               Other                 2   \n",
      "3                          Home               Other                 2   \n",
      "4                          Home               Other                 1   \n",
      "5                          Home            Referral                 3   \n",
      "6                          Home            Referral                 4   \n",
      "...                         ...                 ...               ...   \n",
      "101758                 Facility               Other                 3   \n",
      "101759                 Facility            Transfer                 5   \n",
      "101760                     Home               Other                 1   \n",
      "101761                 Facility               Other                10   \n",
      "101762                     Home               Other                 6   \n",
      "\n",
      "        num_lab_procedures  num_procedures  num_medications  ...  citoglipton  \\\n",
      "2                       11               5               13  ...           No   \n",
      "3                       44               1               16  ...           No   \n",
      "4                       51               0                8  ...           No   \n",
      "5                       31               6               16  ...           No   \n",
      "6                       70               1               21  ...           No   \n",
      "...                    ...             ...              ...  ...          ...   \n",
      "101758                  51               0               16  ...           No   \n",
      "101759                  33               3               18  ...           No   \n",
      "101760                  53               0                9  ...           No   \n",
      "101761                  45               2               21  ...           No   \n",
      "101762                  13               3                3  ...           No   \n",
      "\n",
      "        insulin  glyburide-metformin glipizide-metformin  \\\n",
      "2            No                   No                  No   \n",
      "3            Up                   No                  No   \n",
      "4        Steady                   No                  No   \n",
      "5        Steady                   No                  No   \n",
      "6        Steady                   No                  No   \n",
      "...         ...                  ...                 ...   \n",
      "101758     Down                   No                  No   \n",
      "101759   Steady                   No                  No   \n",
      "101760     Down                   No                  No   \n",
      "101761       Up                   No                  No   \n",
      "101762       No                   No                  No   \n",
      "\n",
      "       glimepiride-pioglitazone metformin-rosiglitazone  \\\n",
      "2                            No                      No   \n",
      "3                            No                      No   \n",
      "4                            No                      No   \n",
      "5                            No                      No   \n",
      "6                            No                      No   \n",
      "...                         ...                     ...   \n",
      "101758                       No                      No   \n",
      "101759                       No                      No   \n",
      "101760                       No                      No   \n",
      "101761                       No                      No   \n",
      "101762                       No                      No   \n",
      "\n",
      "        metformin-pioglitazone change diabetesMed readmitted  \n",
      "2                           No     No         Yes         NO  \n",
      "3                           No     Ch         Yes         NO  \n",
      "4                           No     Ch         Yes         NO  \n",
      "5                           No     No         Yes        >30  \n",
      "6                           No     Ch         Yes         NO  \n",
      "...                        ...    ...         ...        ...  \n",
      "101758                      No     Ch         Yes        >30  \n",
      "101759                      No     No         Yes         NO  \n",
      "101760                      No     Ch         Yes         NO  \n",
      "101761                      No     Ch         Yes         NO  \n",
      "101762                      No     No          No         NO  \n",
      "\n",
      "[100911 rows x 45 columns]\n"
     ]
    }
   ],
   "source": [
    "#data Deletion for satisfying the t=0.5 closeness\n",
    "\n",
    "def calculate_global_distribution(series):\n",
    "    class_distribution = series.value_counts(normalize=True)\n",
    "    global_distribution = class_distribution.to_dict()\n",
    "    return global_distribution\n",
    "\n",
    "def compute_t_closeness(series, global_distribution):\n",
    "    class_distribution = series.value_counts(normalize=True)\n",
    "    combined_index = list(global_distribution.keys())\n",
    "    class_distribution = class_distribution.reindex(combined_index, fill_value=0)\n",
    "\n",
    "    p_values = class_distribution.values\n",
    "    q_values = np.array([global_distribution.get(k, 0) for k in combined_index])\n",
    "\n",
    "    t_closeness = 0.5 * np.sum(np.abs(p_values - q_values))\n",
    "    return t_closeness\n",
    "\n",
    "def calculate_t_closeness(df, quasi_identifiers, sensitive_attributes):\n",
    "    results = []\n",
    "\n",
    "    grouped = df.groupby(quasi_identifiers)\n",
    "    global_distributions = {attribute: calculate_global_distribution(df[attribute]) for attribute in sensitive_attributes}\n",
    "\n",
    "    for group_name, group_df in grouped:\n",
    "        t_closeness_values = {}\n",
    "        for attribute in sensitive_attributes:\n",
    "            series = group_df[attribute]\n",
    "            t_closeness = compute_t_closeness(series, global_distributions[attribute])\n",
    "            t_closeness_values[f't-closeness_{attribute}'] = t_closeness\n",
    "\n",
    "        group_result = {\n",
    "            'Quasi-identifiers': ', '.join(f\"{qi}: {value}\" for qi, value in zip(quasi_identifiers, group_name)),\n",
    "            **t_closeness_values\n",
    "        }\n",
    "        results.append(group_result)\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    return results_df\n",
    "\n",
    "def calculate_k_anonymity(group):\n",
    "    return len(group)\n",
    "\n",
    "def calculate_normalized_entropy(series):\n",
    "    if series.empty:\n",
    "        return 0\n",
    "\n",
    "    value_counts = series.value_counts(normalize=True)\n",
    "    total_entropy = 0\n",
    "\n",
    "    for count in value_counts:\n",
    "        if count > 0:\n",
    "            total_entropy -= count * np.log2(count)\n",
    "\n",
    "    unique_values = series.nunique()\n",
    "    if unique_values == 1:\n",
    "        return 0\n",
    "\n",
    "    normalized_entropy = total_entropy / np.log2(unique_values)\n",
    "    return normalized_entropy\n",
    "\n",
    "def calculate_k_l_values(df, quasi_identifiers, sensitive_attributes):\n",
    "    results = defaultdict(list)\n",
    "    grouped = df.groupby(quasi_identifiers)\n",
    "\n",
    "    for name, group in grouped:\n",
    "        k_anonymity = calculate_k_anonymity(group)\n",
    "        results['Quasi-identifiers'].append(', '.join(f\"{qi}: {value}\" for qi, value in zip(quasi_identifiers, name)))\n",
    "        results['k-anonymity'].append(k_anonymity)\n",
    "\n",
    "        for attribute in sensitive_attributes:\n",
    "            normalized_entropy = calculate_normalized_entropy(group[attribute])\n",
    "            results[f'Normalized Entropy l-diversity_{attribute}'].append(normalized_entropy)\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    return results_df\n",
    "\n",
    "def ensure_privacy(df, quasi_identifiers, sensitive_attributes, t_threshold=0.5, k_threshold=1, l_threshold=0):\n",
    "    while True:\n",
    "        # Calculate k-anonymity and l-diversity\n",
    "        k_l_values = calculate_k_l_values(df, quasi_identifiers, sensitive_attributes)\n",
    "        \n",
    "        # Calculate t-closeness\n",
    "        t_value = calculate_t_closeness(df, quasi_identifiers, sensitive_attributes)\n",
    "        \n",
    "        # Check if all groups satisfy t <= t_threshold, k > k_threshold, and l > l_threshold\n",
    "        k_condition = k_l_values['k-anonymity'] > k_threshold\n",
    "        l_condition = (k_l_values.iloc[:, 2:].astype(float) > l_threshold).all(axis=1)\n",
    "        t_condition = (t_value.iloc[:, 1:].astype(float) <= t_threshold).all(axis=1)\n",
    "        \n",
    "        if k_condition.all() and l_condition.all() and t_condition.all():\n",
    "            break\n",
    "        \n",
    "        # Identify groups that don't satisfy the conditions\n",
    "        groups_to_delete = []\n",
    "        for idx in range(len(k_l_values)):\n",
    "            if not (k_condition[idx] and l_condition[idx] and t_condition[idx]):\n",
    "                groups_to_delete.append(k_l_values['Quasi-identifiers'][idx])\n",
    "        \n",
    "        # Delete the identified groups\n",
    "        df = df[~df.apply(lambda row: ', '.join(f\"{qi}: {row[qi]}\" for qi in quasi_identifiers) in groups_to_delete, axis=1)]\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Example usage:\n",
    "# Assuming `df` is the DataFrame with your data\n",
    "quasi_identifiers = ['race', 'gender', 'age']\n",
    "sensitive_attributes = ['diag_1', 'diag_2', 'diag_3', 'max_glu_serum', 'A1Cresult', 'readmitted']\n",
    "\n",
    "# Ensure the dataset satisfies t-closeness, k-anonymity, and l-diversity thresholds\n",
    "filtered_df = ensure_privacy(df, quasi_identifiers, sensitive_attributes, t_threshold=0.5, k_threshold=1, l_threshold=0)\n",
    "\n",
    "print(\"Filtered DataFrame:\")\n",
    "print(filtered_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da1336da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P_29 Score: 0.8375317503843992\n",
      "Reasons: []\n",
      "Problematic Information:\n",
      "Minimum k-anonymity: 195\n",
      "Minimum normalized l-value: 0.07358616908386309\n",
      "Maximum t-value: 0.4574499284491258\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "def calculate_k_anonymity(group):\n",
    "    return len(group)\n",
    "\n",
    "def calculate_normalized_entropy(series):\n",
    "    if series.empty:\n",
    "        return 0\n",
    "\n",
    "    value_counts = series.value_counts(normalize=True)\n",
    "    total_entropy = 0\n",
    "\n",
    "    for count in value_counts:\n",
    "        if count > 0:\n",
    "            total_entropy -= count * np.log2(count)\n",
    "\n",
    "    unique_values = series.nunique()\n",
    "    if unique_values == 1:\n",
    "        return 0\n",
    "\n",
    "    normalized_entropy = total_entropy / np.log2(unique_values)\n",
    "    return normalized_entropy\n",
    "\n",
    "def calculate_global_distribution(series):\n",
    "    class_distribution = series.value_counts(normalize=True)\n",
    "    global_distribution = class_distribution.to_dict()\n",
    "    return global_distribution\n",
    "\n",
    "def compute_t_closeness(series, global_distribution):\n",
    "    class_distribution = series.value_counts(normalize=True)\n",
    "    combined_index = list(global_distribution.keys())\n",
    "    class_distribution = class_distribution.reindex(combined_index, fill_value=0)\n",
    "\n",
    "    p_values = class_distribution.values\n",
    "    q_values = np.array([global_distribution.get(k, 0) for k in combined_index])\n",
    "\n",
    "    t_closeness = 0.5 * np.sum(np.abs(p_values - q_values))\n",
    "    return t_closeness\n",
    "\n",
    "def calculate_t_closeness(df, quasi_identifiers, sensitive_attributes):\n",
    "    results = []\n",
    "\n",
    "    grouped = df.groupby(quasi_identifiers)\n",
    "    global_distributions = {attribute: calculate_global_distribution(df[attribute]) for attribute in sensitive_attributes}\n",
    "\n",
    "    for group_name, group_df in grouped:\n",
    "        t_closeness_values = {}\n",
    "        for attribute in sensitive_attributes:\n",
    "            series = group_df[attribute]\n",
    "            t_closeness = compute_t_closeness(series, global_distributions[attribute])\n",
    "            t_closeness_values[f't-closeness_{attribute}'] = t_closeness\n",
    "\n",
    "        group_result = {\n",
    "            'Quasi-identifiers': ', '.join(f\"{qi}: {value}\" for qi, value in zip(quasi_identifiers, group_name)),\n",
    "            **t_closeness_values\n",
    "        }\n",
    "        results.append(group_result)\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    return results_df\n",
    "\n",
    "def calculate_P_29_score(k_value, l_value, t_value, w_k=0.5, w_l=0.25, w_t=0.25):\n",
    "    reasons = []\n",
    "    problematic_info = []\n",
    "\n",
    "    k_min = k_value['k-anonymity'].min()\n",
    "\n",
    "    if k_min == 1:\n",
    "        reasons.append(\"k-anonymity is 1\")\n",
    "        problematic_rows = k_value[k_value['k-anonymity'] == 1]['Quasi-identifiers'].tolist()\n",
    "        problematic_info.extend([(row, \"k-anonymity is 1\") for row in problematic_rows])\n",
    "\n",
    "    if l_value.iloc[:, 1:].eq(0).any().any():\n",
    "        reasons.append(\"normalized entropy l-value is 0 for some attribute\")\n",
    "        for col in l_value.columns[1:]:\n",
    "            problematic_rows = l_value[l_value[col] == 0]['Quasi-identifiers'].tolist()\n",
    "            problematic_info.extend([(row, f\"normalized entropy l-value is 0 for {col}\") for row in problematic_rows])\n",
    "\n",
    "    if (t_value.iloc[:, 1:].astype(float) > 0.5).any().any():\n",
    "        reasons.append(\"t-value exceeds 0.5 for some attribute\")\n",
    "        for col in t_value.columns[1:]:\n",
    "            if t_value[col].dtype != 'object':\n",
    "                problematic_rows = t_value[t_value[col].astype(float) > 0.5]['Quasi-identifiers'].tolist()\n",
    "                problematic_info.extend([(row, f\"t-value exceeds 0.5 for {col}\") for row in problematic_rows])\n",
    "\n",
    "    if k_min == 1 or l_value.iloc[:, 1:].eq(0).any().any() or (t_value.iloc[:, 1:].astype(float) > 0.5).any().any():\n",
    "        return 0.0, problematic_info, reasons, k_min, l_value.iloc[:, 1:].min().min(), t_value.iloc[:, 1:].max().max()\n",
    "\n",
    "    column_means = l_value.iloc[:, 1:].mean()\n",
    "    normalized_l_value = column_means.mean()\n",
    "\n",
    "    t_value_normalized = t_value.copy()\n",
    "    for column in t_value.columns[1:]:\n",
    "        min_val = t_value[column].min()\n",
    "        max_val = t_value[column].max()\n",
    "        t_value_normalized[column] = (t_value[column] - min_val) / (max_val - min_val)\n",
    "\n",
    "    normalized_t_value = t_value_normalized.iloc[:, 1:].mean().mean()\n",
    "\n",
    "    P_29_score = w_k * (1 - (1 / k_min)) + w_l * normalized_l_value + w_t * (1 - normalized_t_value)\n",
    "\n",
    "    return P_29_score, problematic_info, reasons, k_min, l_value.iloc[:, 1:].min().min(), t_value.iloc[:, 1:].max().max()\n",
    "\n",
    "def analyze_privacy(df, quasi_identifiers, sensitive_attributes):\n",
    "    results = defaultdict(list)\n",
    "\n",
    "    grouped = df.groupby(quasi_identifiers)\n",
    "    for name, group in grouped:\n",
    "        k_anonymity = calculate_k_anonymity(group)\n",
    "\n",
    "        for attribute in sensitive_attributes:\n",
    "            normalized_entropy = calculate_normalized_entropy(group[attribute])\n",
    "            results[f'Normalized Entropy l-diversity_{attribute}'].append(normalized_entropy)\n",
    "\n",
    "        quasi_identifier_values = ', '.join(f\"{qi}: {group[qi].iloc[0]}\" for qi in quasi_identifiers)\n",
    "        results['Quasi-identifiers'].append(quasi_identifier_values)\n",
    "        results['k-anonymity'].append(k_anonymity)\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    t_value = calculate_t_closeness(df, quasi_identifiers, sensitive_attributes)\n",
    "\n",
    "    k_value = results_df[['Quasi-identifiers', 'k-anonymity']].copy()\n",
    "    l_value_columns = ['Quasi-identifiers'] + [col for col in results_df.columns if col.startswith('Normalized Entropy l-diversity')]\n",
    "    l_value = results_df[l_value_columns].copy()\n",
    "\n",
    "    P_29_score, problematic_info, reasons, k_min, min_l_value, max_t_value = calculate_P_29_score(k_value, l_value, t_value)\n",
    "\n",
    "    return {\n",
    "        \"P_29_score\": P_29_score,\n",
    "        \"problematic_info\": problematic_info,\n",
    "        \"reasons\": reasons,\n",
    "        \"k_min\": k_min,\n",
    "        \"min_l_value\": min_l_value,\n",
    "        \"max_t_value\": max_t_value,\n",
    "        \"k_value\": k_value,\n",
    "        \"l_value\": l_value,\n",
    "        \"t_value\": t_value\n",
    "    }\n",
    "\n",
    "# Example usage:\n",
    "# Assuming `df` is the DataFrame with your data\n",
    "quasi_identifiers = ['race', 'gender', 'age']\n",
    "sensitive_attributes = ['diag_1', 'diag_2', 'diag_3', 'max_glu_serum', 'A1Cresult', 'readmitted']\n",
    "\n",
    "# Calculate privacy metrics and P_29 score\n",
    "privacy_results = analyze_privacy(filtered_df, quasi_identifiers, sensitive_attributes)\n",
    "\n",
    "# Display results\n",
    "print(\"P_29 Score:\", privacy_results[\"P_29_score\"])\n",
    "print(\"Reasons:\", privacy_results[\"reasons\"])\n",
    "print(\"Problematic Information:\")\n",
    "for info in privacy_results[\"problematic_info\"]:\n",
    "    print(f\"Problem in {info[0]} due to {info[1]}\")\n",
    "print(\"Minimum k-anonymity:\", privacy_results[\"k_min\"])\n",
    "print(\"Minimum normalized l-value:\", privacy_results[\"min_l_value\"])\n",
    "print(\"Maximum t-value:\", privacy_results[\"max_t_value\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45adf690",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = 'df5-filter.csv'\n",
    "filtered_df.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b39b398",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e50267b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760c4c92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e314728",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d720afd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e53df1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3e0a15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fed627",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4139a31c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
