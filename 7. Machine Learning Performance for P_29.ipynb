{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5deb63f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "df_original = pd.read_csv('originaldf.csv')\n",
    "\n",
    "dft1= pd.read_csv('df1-v.csv')\n",
    "dft2= pd.read_csv('df2-v.csv')\n",
    "dft3= pd.read_csv('df3-v.csv')\n",
    "dft4= pd.read_csv('df4-v.csv')\n",
    "dft5= pd.read_csv('df5-v.csv')\n",
    "\n",
    "\n",
    "readmitted_mapping = {'<30': 1, '>30': 0, 'NO': 0}\n",
    "df_original['readmitted'] = df_original['readmitted'].map(readmitted_mapping)\n",
    "dft1['readmitted'] = dft1['readmitted'].map(readmitted_mapping)\n",
    "dft2['readmitted'] = dft2['readmitted'].map(readmitted_mapping)\n",
    "dft3['readmitted'] = dft3['readmitted'].map(readmitted_mapping)\n",
    "dft4['readmitted'] = dft4['readmitted'].map(readmitted_mapping)\n",
    "dft5['readmitted'] = dft5['readmitted'].map(readmitted_mapping)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf8f2588",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "\n",
    "def encode_categorical_features(df, exclude_columns=None):\n",
    "    \"\"\"Encode categorical features using dummy encoding or binary encoding based on the number of unique values,\n",
    "    while excluding specified columns from encoding.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame containing features to be encoded.\n",
    "        exclude_columns (list): List of columns to exclude from encoding.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with encoded features.\n",
    "        dict: Dictionary mapping each original column name to the encoding type used.\n",
    "    \"\"\"\n",
    "    encoded_df = df.copy()\n",
    "    encoding_info = {}\n",
    "    if exclude_columns is None:\n",
    "        exclude_columns = []\n",
    "    \n",
    "    categorical_columns = encoded_df.select_dtypes(include=['object', 'category']).columns\n",
    "    \n",
    "    for column in categorical_columns:\n",
    "        if column in exclude_columns:\n",
    "            encoding_info[column] = \"Excluded\"\n",
    "            continue\n",
    "        \n",
    "        unique_values = encoded_df[column].nunique()\n",
    "        if unique_values == 2 or unique_values == 1:\n",
    "            value_mapping = {label: idx for idx, label in enumerate(encoded_df[column].unique())}\n",
    "            encoded_df[column] = encoded_df[column].map(value_mapping)\n",
    "            encoding_info[column] = \"Binary Encoding\"\n",
    "        elif unique_values >= 3:\n",
    "            dummies = pd.get_dummies(encoded_df[column], prefix=column)\n",
    "            encoded_df = pd.concat([encoded_df, dummies], axis=1)\n",
    "            encoded_df.drop(column, axis=1, inplace=True)\n",
    "            encoding_info[column] = \"Dummy Encoding\"\n",
    "    \n",
    "    return encoded_df, encoding_info\n",
    "\n",
    "def run_multivariable_logistic_regression(encoded_df, target_column):\n",
    "    \"\"\"\n",
    "    Runs a Multivariable Logistic Regression model on the provided encoded DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    - encoded_df: The encoded DataFrame.\n",
    "    - target_column: The name of the target column in the DataFrame.\n",
    "    \n",
    "    Returns:\n",
    "    - dict: Dictionary containing the model, accuracy, and predictions.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        X = encoded_df.drop(target_column, axis=1)\n",
    "        y = encoded_df[target_column]\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        model = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000, random_state=42)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        accuracy = model.score(X_test, y_test)\n",
    "        predictions = model.predict(X_test)\n",
    "\n",
    "        return {\n",
    "            \"model\": model,\n",
    "            \"accuracy\": accuracy,\n",
    "            \"predictions\": predictions,\n",
    "            \"model_name\": \"Multivariable Logistic Regression\"\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error running Multivariable Logistic Regression: {e}\")\n",
    "        return None\n",
    "\n",
    "def run_random_forest(encoded_df, target_column):\n",
    "    \"\"\"\n",
    "    Runs a Random Forest model on the provided encoded DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    - encoded_df: The encoded DataFrame.\n",
    "    - target_column: The name of the target column in the DataFrame.\n",
    "    \n",
    "    Returns:\n",
    "    - dict: Dictionary containing the model, accuracy, and predictions.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        X = encoded_df.drop(target_column, axis=1)\n",
    "        y = encoded_df[target_column]\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        accuracy = model.score(X_test, y_test)\n",
    "        predictions = model.predict(X_test)\n",
    "\n",
    "        return {\n",
    "            \"model\": model,\n",
    "            \"accuracy\": accuracy,\n",
    "            \"predictions\": predictions,\n",
    "            \"model_name\": \"Random Forest\"\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error running Random Forest: {e}\")\n",
    "        return None\n",
    "\n",
    "def run_xgboost(encoded_df, target_column):\n",
    "    \"\"\"\n",
    "    Runs an XGBoost model on the provided encoded DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    - encoded_df: The encoded DataFrame.\n",
    "    - target_column: The name of the target column in the DataFrame.\n",
    "    \n",
    "    Returns:\n",
    "    - dict: Dictionary containing the model, accuracy, and predictions.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        X = encoded_df.drop(target_column, axis=1)\n",
    "        y = encoded_df[target_column]\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        # Rename columns to ensure they are valid feature names for XGBoost\n",
    "        X_train.columns = [f\"feature_{i}\" for i in range(X_train.shape[1])]\n",
    "        X_test.columns = [f\"feature_{i}\" for i in range(X_test.shape[1])]\n",
    "\n",
    "        model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        accuracy = model.score(X_test, y_test)\n",
    "        predictions = model.predict(X_test)\n",
    "\n",
    "        return {\n",
    "            \"model\": model,\n",
    "            \"accuracy\": accuracy,\n",
    "            \"predictions\": predictions,\n",
    "            \"model_name\": \"XGBoost\"\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error running XGBoost: {e}\")\n",
    "        return None\n",
    "\n",
    "def run_ml_models(encoded_df, target_column):\n",
    "    \"\"\"\n",
    "    Runs Multivariable Logistic Regression, Random Forest, and XGBoost models on the provided encoded DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    - encoded_df: The encoded DataFrame.\n",
    "    - target_column: The name of the target column in the DataFrame.\n",
    "    \n",
    "    Returns:\n",
    "    - dict: Dictionary containing the results for all models.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    lr_result = run_multivariable_logistic_regression(encoded_df, target_column)\n",
    "    if lr_result is not None:\n",
    "        results[\"Multivariable Logistic Regression\"] = lr_result\n",
    "        print(f\"Accuracy for Multivariable Logistic Regression: {lr_result['accuracy']:.2f}\")\n",
    "\n",
    "    rf_result = run_random_forest(encoded_df, target_column)\n",
    "    if rf_result is not None:\n",
    "        results[\"Random Forest\"] = rf_result\n",
    "        print(f\"Accuracy for Random Forest: {rf_result['accuracy']:.2f}\")\n",
    "\n",
    "    xgb_result = run_xgboost(encoded_df, target_column)\n",
    "    if xgb_result is not None:\n",
    "        results[\"XGBoost\"] = xgb_result\n",
    "        print(f\"Accuracy for XGBoost: {xgb_result['accuracy']:.2f}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "# Example usage:\n",
    "# Assuming 'df' is your DataFrame and 'target_column' is the name of your target column\n",
    "\n",
    "# Encode categorical features\n",
    "# encoded_df, encoding_info = encode_categorical_features(df, exclude_columns=[target_column])\n",
    "\n",
    "# Run the models\n",
    "# results = run_ml_models(encoded_df, target_column)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e130125b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding Information:\n",
      "race: Dummy Encoding\n",
      "gender: Binary Encoding\n",
      "age: Dummy Encoding\n",
      "discharge_disposition_id: Dummy Encoding\n",
      "admission_source_id: Dummy Encoding\n",
      "diag_1: Dummy Encoding\n",
      "diag_2: Dummy Encoding\n",
      "diag_3: Dummy Encoding\n",
      "max_glu_serum: Dummy Encoding\n",
      "A1Cresult: Dummy Encoding\n",
      "metformin: Dummy Encoding\n",
      "repaglinide: Dummy Encoding\n",
      "nateglinide: Dummy Encoding\n",
      "chlorpropamide: Dummy Encoding\n",
      "glimepiride: Dummy Encoding\n",
      "acetohexamide: Binary Encoding\n",
      "glipizide: Dummy Encoding\n",
      "glyburide: Dummy Encoding\n",
      "tolbutamide: Binary Encoding\n",
      "pioglitazone: Dummy Encoding\n",
      "rosiglitazone: Dummy Encoding\n",
      "acarbose: Dummy Encoding\n",
      "miglitol: Dummy Encoding\n",
      "troglitazone: Binary Encoding\n",
      "tolazamide: Dummy Encoding\n",
      "examide: Binary Encoding\n",
      "citoglipton: Binary Encoding\n",
      "insulin: Dummy Encoding\n",
      "glyburide-metformin: Dummy Encoding\n",
      "glipizide-metformin: Binary Encoding\n",
      "glimepiride-pioglitazone: Binary Encoding\n",
      "metformin-rosiglitazone: Binary Encoding\n",
      "metformin-pioglitazone: Binary Encoding\n",
      "change: Binary Encoding\n",
      "diabetesMed: Binary Encoding\n",
      "\n",
      "Encoded DataFrame:\n",
      "   gender  admission_type_id  time_in_hospital  num_lab_procedures  \\\n",
      "0       0                  0                 1                  41   \n",
      "1       0                  1                 3                  59   \n",
      "2       0                  1                 2                  11   \n",
      "3       1                  1                 2                  44   \n",
      "4       1                  1                 1                  51   \n",
      "\n",
      "   num_procedures  num_medications  number_outpatient  number_emergency  \\\n",
      "0               0                1                  0                 0   \n",
      "1               0               18                  0                 0   \n",
      "2               5               13                  2                 0   \n",
      "3               1               16                  0                 0   \n",
      "4               0                8                  0                 0   \n",
      "\n",
      "   number_inpatient  number_diagnoses  ...  tolazamide_Steady  tolazamide_Up  \\\n",
      "0                 0                 1  ...                  0              0   \n",
      "1                 0                 9  ...                  0              0   \n",
      "2                 1                 6  ...                  0              0   \n",
      "3                 0                 7  ...                  0              0   \n",
      "4                 0                 5  ...                  0              0   \n",
      "\n",
      "   insulin_Down  insulin_No  insulin_Steady  insulin_Up  \\\n",
      "0             0           1               0           0   \n",
      "1             0           0               0           1   \n",
      "2             0           1               0           0   \n",
      "3             0           0               0           1   \n",
      "4             0           0               1           0   \n",
      "\n",
      "   glyburide-metformin_Down  glyburide-metformin_No  \\\n",
      "0                         0                       1   \n",
      "1                         0                       1   \n",
      "2                         0                       1   \n",
      "3                         0                       1   \n",
      "4                         0                       1   \n",
      "\n",
      "   glyburide-metformin_Steady  glyburide-metformin_Up  \n",
      "0                           0                       0  \n",
      "1                           0                       0  \n",
      "2                           0                       0  \n",
      "3                           0                       0  \n",
      "4                           0                       0  \n",
      "\n",
      "[5 rows x 141 columns]\n"
     ]
    }
   ],
   "source": [
    "# Encode categorical features in the original dataset\n",
    "encoded_df, encoding_info = encode_categorical_features(df_original, exclude_columns=['readmitted'])\n",
    "\n",
    "# Print encoding information\n",
    "print(\"Encoding Information:\")\n",
    "for column, encoding_type in encoding_info.items():\n",
    "    print(f\"{column}: {encoding_type}\")\n",
    "\n",
    "# Display encoded DataFrame\n",
    "print(\"\\nEncoded DataFrame:\")\n",
    "print(encoded_df.head())\n",
    "\n",
    "# Optionally, encode categorical features in noisy datasets\n",
    "encoded_dfts = []\n",
    "for dft in [dft1, dft2, dft3, dft4, dft5]:\n",
    "    encoded_dft, _ = encode_categorical_features(dft, exclude_columns=['readmitted'])\n",
    "    encoded_dfts.append(encoded_dft)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "880bb701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for Original Dataset:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fanfan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1237: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/Users/fanfan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Multivariable Logistic Regression: 0.89\n",
      "Accuracy for Random Forest: 0.89\n",
      "Accuracy for XGBoost: 0.89\n",
      "\n",
      "Results:\n",
      "\n",
      "Multivariable Logistic Regression Results:\n",
      "Accuracy: 0.88847\n",
      "Predictions: [0 0 0 ... 1 0 0]\n",
      "\n",
      "Random Forest Results:\n",
      "Accuracy: 0.88916\n",
      "Predictions: [0 0 0 ... 0 0 0]\n",
      "\n",
      "XGBoost Results:\n",
      "Accuracy: 0.88773\n",
      "Predictions: [0 0 0 ... 0 0 0]\n",
      "\n",
      "Results for dft1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fanfan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1237: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Multivariable Logistic Regression: 0.89\n",
      "Accuracy for Random Forest: 0.89\n",
      "Accuracy for XGBoost: 0.89\n",
      "Multivariable Logistic Regression Accuracy: 0.88928\n",
      "Random Forest Accuracy: 0.88943\n",
      "XGBoost Accuracy: 0.88877\n",
      "\n",
      "Results for dft2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fanfan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1237: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Multivariable Logistic Regression: 0.89\n",
      "Accuracy for Random Forest: 0.89\n",
      "Accuracy for XGBoost: 0.89\n",
      "Multivariable Logistic Regression Accuracy: 0.88782\n",
      "Random Forest Accuracy: 0.88812\n",
      "XGBoost Accuracy: 0.88673\n",
      "\n",
      "Results for dft3:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fanfan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1237: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/Users/fanfan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Multivariable Logistic Regression: 0.89\n",
      "Accuracy for Random Forest: 0.89\n",
      "Accuracy for XGBoost: 0.89\n",
      "Multivariable Logistic Regression Accuracy: 0.88782\n",
      "Random Forest Accuracy: 0.88843\n",
      "XGBoost Accuracy: 0.88680\n",
      "\n",
      "Results for dft4:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fanfan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1237: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/Users/fanfan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Multivariable Logistic Regression: 0.89\n",
      "Accuracy for Random Forest: 0.89\n",
      "Accuracy for XGBoost: 0.89\n",
      "Multivariable Logistic Regression Accuracy: 0.88797\n",
      "Random Forest Accuracy: 0.88838\n",
      "XGBoost Accuracy: 0.88725\n",
      "\n",
      "Results for dft5:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fanfan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1237: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, binary problems will be fit as proper binary  logistic regression models (as if multi_class='ovr' were set). Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/Users/fanfan/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Multivariable Logistic Regression: 0.89\n",
      "Accuracy for Random Forest: 0.89\n",
      "Accuracy for XGBoost: 0.89\n",
      "Multivariable Logistic Regression Accuracy: 0.88757\n",
      "Random Forest Accuracy: 0.88845\n",
      "XGBoost Accuracy: 0.88710\n"
     ]
    }
   ],
   "source": [
    "target_column = 'readmitted'\n",
    "\n",
    "# Run models on the original dataset\n",
    "print(\"\\nResults for Original Dataset:\")\n",
    "results_original = run_ml_models(encoded_df, target_column)\n",
    "\n",
    "# Print results for original dataset\n",
    "print(\"\\nResults:\")\n",
    "for model_name, result in results_original.items():\n",
    "    print(f\"\\n{model_name} Results:\")\n",
    "    print(f\"Accuracy: {result['accuracy']:.5f}\")\n",
    "    print(f\"Predictions: {result['predictions']}\")\n",
    "\n",
    "# Optionally, run models on each noisy dataset\n",
    "for i, encoded_dft in enumerate(encoded_dfts, start=1):\n",
    "    print(f\"\\nResults for dft{i}:\")\n",
    "    dft_results = run_ml_models(encoded_dft, target_column)\n",
    "    for model_name, result in dft_results.items():\n",
    "        print(f\"{model_name} Accuracy: {result['accuracy']:.5f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "727a81ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  DataFrame  P_29 Score\n",
      "0     df1-v    0.804851\n",
      "1     df2-v    0.828066\n",
      "2     df3-v    0.832673\n",
      "3     df4-v    0.838194\n",
      "4     df5-v    0.841095\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a dictionary with the information\n",
    "data = {\n",
    "    'DataFrame': ['df1-v', 'df2-v', 'df3-v', 'df4-v', 'df5-v'],\n",
    "    'P_29 Score': [\n",
    "        0.8048508675661077,\n",
    "        0.8280657743789652,\n",
    "        0.832672944696338,\n",
    "        0.8381942262639237,\n",
    "        0.8410949233514133\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create the DataFrame\n",
    "df_scores = pd.DataFrame(data)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4c389cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  DataFrame  Multivariable Logistic Regression  Random Forest  XGBoost\n",
      "0     df1-v                            0.88928        0.88943  0.88877\n",
      "1     df2-v                            0.88782        0.88812  0.88673\n",
      "2     df3-v                            0.88782        0.88843  0.88680\n",
      "3     df4-v                            0.88797        0.88838  0.88725\n",
      "4     df5-v                            0.88757        0.88845  0.88710\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Data for each dataset and their respective accuracies\n",
    "data = {\n",
    "    'DataFrame': ['df1-v', 'df2-v', 'df3-v', 'df4-v', 'df5-v'],\n",
    "    'Multivariable Logistic Regression': [0.88928, 0.88782, 0.88782, 0.88797, 0.88757],\n",
    "    'Random Forest': [0.88943, 0.88812, 0.88843, 0.88838, 0.88845],\n",
    "    'XGBoost': [0.88877, 0.88673, 0.88680, 0.88725, 0.88710]\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df_results = pd.DataFrame(data)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3cfa3d85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DataFrame</th>\n",
       "      <th>P_29 Score</th>\n",
       "      <th>Multivariable Logistic Regression</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>df1-v</td>\n",
       "      <td>0.804851</td>\n",
       "      <td>0.88928</td>\n",
       "      <td>0.88943</td>\n",
       "      <td>0.88877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>df2-v</td>\n",
       "      <td>0.828066</td>\n",
       "      <td>0.88782</td>\n",
       "      <td>0.88812</td>\n",
       "      <td>0.88673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>df3-v</td>\n",
       "      <td>0.832673</td>\n",
       "      <td>0.88782</td>\n",
       "      <td>0.88843</td>\n",
       "      <td>0.88680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>df4-v</td>\n",
       "      <td>0.838194</td>\n",
       "      <td>0.88797</td>\n",
       "      <td>0.88838</td>\n",
       "      <td>0.88725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>df5-v</td>\n",
       "      <td>0.841095</td>\n",
       "      <td>0.88757</td>\n",
       "      <td>0.88845</td>\n",
       "      <td>0.88710</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  DataFrame  P_29 Score  Multivariable Logistic Regression  Random Forest  \\\n",
       "0     df1-v    0.804851                            0.88928        0.88943   \n",
       "1     df2-v    0.828066                            0.88782        0.88812   \n",
       "2     df3-v    0.832673                            0.88782        0.88843   \n",
       "3     df4-v    0.838194                            0.88797        0.88838   \n",
       "4     df5-v    0.841095                            0.88757        0.88845   \n",
       "\n",
       "   XGBoost  \n",
       "0  0.88877  \n",
       "1  0.88673  \n",
       "2  0.88680  \n",
       "3  0.88725  \n",
       "4  0.88710  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Data for P_29 Score\n",
    "data_scores = {\n",
    "    'DataFrame': ['df1-v', 'df2-v', 'df3-v', 'df4-v', 'df5-v'],\n",
    "    'P_29 Score': [\n",
    "        0.8048508675661077,\n",
    "        0.8280657743789652,\n",
    "        0.832672944696338,\n",
    "        0.8381942262639237,\n",
    "        0.8410949233514133\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create the DataFrame for P_29 Scores\n",
    "df_scores = pd.DataFrame(data_scores)\n",
    "\n",
    "# Data for accuracies\n",
    "data_results = {\n",
    "    'DataFrame': ['df1-v', 'df2-v', 'df3-v', 'df4-v', 'df5-v'],\n",
    "    'Multivariable Logistic Regression': [0.88928, 0.88782, 0.88782, 0.88797, 0.88757],\n",
    "    'Random Forest': [0.88943, 0.88812, 0.88843, 0.88838, 0.88845],\n",
    "    'XGBoost': [0.88877, 0.88673, 0.88680, 0.88725, 0.88710]\n",
    "}\n",
    "\n",
    "# Create the DataFrame for accuracies\n",
    "df_results = pd.DataFrame(data_results)\n",
    "\n",
    "# Merge the two DataFrames based on 'DataFrame'\n",
    "merged_df = pd.merge(df_scores, df_results, on='DataFrame')\n",
    "\n",
    "# Print the merged DataFrame\n",
    "merged_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c970c650",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
